# -*- coding: utf-8 -*-
"""SegCaps_chang_lin_li.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-TTNqJ0ATiafRJEOWDVDaBGfZ4Y9U9HG
"""

import keras
from keras.models import Sequential,Model
from keras.utils import np_utils
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Input
from keras.layers import Conv2D, MaxPooling2D,UpSampling2D,concatenate,add, ZeroPadding2D
from keras import regularizers
from keras.callbacks import LearningRateScheduler, ModelCheckpoint,TensorBoard, ReduceLROnPlateau
import numpy as np
from keras.optimizers import Adam,SGD
import tensorflow as tf
import os
from keras.callbacks import ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau,EarlyStopping,CSVLogger
from keras.utils import multi_gpu_model
from sklearn.utils import class_weight
print(keras.__version__)

import os
os.environ["CUDA_VISIBLE_DEVICES"]="6"

import os
os.chdir('/home/jenyrajan/Major_Project_Seg_Caps_2020/Positive_Random')
cwd = os.getcwd() 
print("Current working directory is:", cwd)

print('Train data Details----------------------------------')
xtrain=np.load('3_F_P_Train_Data.npy')
ytrain=np.load('3_F_P_Train_GT.npy')

xtrain= xtrain.reshape(-1,256,256,1)
ytrain= ytrain.reshape(-1,256,256,1)

xtrain= xtrain.astype('float32')/255
ytrain= ytrain.astype('float32')

print(xtrain.shape, ytrain.shape)
print('max:',np.max(xtrain))
print('min:',np.min(ytrain))


print('Validation data Details----------------------------------')
xval=np.load('3_F_P_Valid_Data.npy')
yval=np.load('3_F_P_Valid_GT.npy')

xval= xval.reshape(-1,256,256,1)
yval= yval.reshape(-1,256,256,1)

xval= xval.astype('float32')/255
yval= yval.astype('float32')

print(xval.shape, yval.shape)
print('max:',np.max(xval))
print('min:',np.min(yval))

print('Test data Details----------------------------------')
xtest=np.load('3_F_P_Test_Data.npy')
ytest=np.load('3_F_P_Test_GT.npy')

xtest= xtest.reshape(-1,256,256,1)
ytest= ytest.reshape(-1,256,256,1)

xtest= xtest.astype('float32')/255
ytest= ytest.astype('float32')

print(xtest.shape, ytest.shape)
print('max:',np.max(xtest))
print('min:',np.min(ytest))


"""print(np.max(ytrain[66]))
for j in range (256):
    print(ytrain[66][j])
    

temp_t= xtrain*ytrain


import matplotlib.pyplot as plt
plt.subplot(121).imshow(np.squeeze(temp_t[188]),cmap='gray')
plt.subplot(122).imshow(np.squeeze(ytrain[188]),cmap='gray')
plt.show()"""

############################################################### Model Start ##################################################################
import keras.backend as K
import tensorflow as tf
from keras import initializers, layers
from keras.utils.conv_utils import conv_output_length, deconv_length
import numpy as np

class Length(layers.Layer):
    def __init__(self, num_classes, seg=True, **kwargs):
        super(Length, self).__init__(**kwargs)
        if num_classes == 2:
            self.num_classes = 1
        else:
            self.num_classes = num_classes
        self.seg = seg

    def call(self, inputs, **kwargs):
        if inputs.get_shape().ndims == 5:
            assert inputs.get_shape()[-2].value == 1, 'Error: Must have num_capsules = 1 going into Length'
            inputs = K.squeeze(inputs, axis=-2)
        return K.expand_dims(tf.norm(inputs, axis=-1), axis=-1)

    def compute_output_shape(self, input_shape):
        if len(input_shape) == 5:
            input_shape = input_shape[0:-2] + input_shape[-1:]
        if self.seg:
            return input_shape[:-1] + (self.num_classes,)
        else:
            return input_shape[:-1]

    def get_config(self):
        config = {'num_classes': self.num_classes, 'seg': self.seg}
        base_config = super(Length, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


class Mask(layers.Layer):
    def __init__(self, resize_masks=False, **kwargs):
        super(Mask, self).__init__(**kwargs)
        self.resize_masks = resize_masks

    def call(self, inputs, **kwargs):
        if type(inputs) is list: # The true label is used to mask the output of capsule layer. For training
            assert len(inputs) == 2
            input, mask = inputs #(?, 512, 512, 1, 16), (?, 512, 512, 1)
            _, hei, wid, _, _ = input.get_shape()
            if self.resize_masks:
                mask = tf.image.resize_bicubic(mask, (hei.value, wid.value))
            mask = K.expand_dims(mask, -1) #mask = (?, 512, 512, 1, 1)
            if input.get_shape().ndims == 3:
                masked = K.batch_flatten(mask * input)
            else:
                masked = mask * input

        else: # Mask using the capsule with maximal length. For prediction
            if inputs.get_shape().ndims == 3:
                x = K.sqrt(K.sum(K.square(inputs), -1))
                mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])
                masked = K.batch_flatten(K.expand_dims(mask, -1) * inputs)
            else:
                masked = inputs

        return masked

    def compute_output_shape(self, input_shape):
        if type(input_shape[0]) is tuple:  # true label provided
            if len(input_shape[0]) == 3:
                return tuple([None, input_shape[0][1] * input_shape[0][2]])
            else:
                return input_shape[0]
        else:  # no true label provided
            if len(input_shape) == 3:
                return tuple([None, input_shape[1] * input_shape[2]])
            else:
                return input_shape

    def get_config(self):
        config = {'resize_masks': self.resize_masks}
        base_config = super(Mask, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


class ConvCapsuleLayer(layers.Layer):
    def __init__(self, kernel_size, num_capsule, num_atoms, strides=1, padding='same', routings=3,
                 kernel_initializer='he_normal', **kwargs):
        super(ConvCapsuleLayer, self).__init__(**kwargs)
        self.kernel_size = kernel_size
        self.num_capsule = num_capsule
        self.num_atoms = num_atoms
        self.strides = strides
        self.padding = padding
        self.routings = routings
        self.kernel_initializer = initializers.get(kernel_initializer)

    def build(self, input_shape):
        assert len(input_shape) == 5, "The input Tensor should have shape=[None, input_height, input_width," \
                                      " input_num_capsule, input_num_atoms]"
        self.input_height = input_shape[1]
        self.input_width = input_shape[2]
        self.input_num_capsule = input_shape[3]
        self.input_num_atoms = input_shape[4]

        # Transform matrix
        self.W = self.add_weight(shape=[self.kernel_size, self.kernel_size,
                                 self.input_num_atoms, self.num_capsule * self.num_atoms],
                                 initializer=self.kernel_initializer,
                                 name='W')

        self.b = self.add_weight(shape=[1, 1, self.num_capsule, self.num_atoms],
                                 initializer=initializers.constant(0.1),
                                 name='b')

        self.built = True

    def call(self, input_tensor, training=None):

        input_transposed = tf.transpose(input_tensor, [3, 0, 1, 2, 4])
        input_shape = K.shape(input_transposed)
        input_tensor_reshaped = K.reshape(input_transposed, [
            input_shape[0] * input_shape[1], self.input_height, self.input_width, self.input_num_atoms])
        input_tensor_reshaped.set_shape((None, self.input_height, self.input_width, self.input_num_atoms))

        conv = K.conv2d(input_tensor_reshaped, self.W, (self.strides, self.strides),
                        padding=self.padding, data_format='channels_last')

        votes_shape = K.shape(conv)
        _, conv_height, conv_width, _ = conv.get_shape()

        votes = K.reshape(conv, [input_shape[1], input_shape[0], votes_shape[1], votes_shape[2],
                                 self.num_capsule, self.num_atoms])
        votes.set_shape((None, self.input_num_capsule, conv_height.value, conv_width.value,
                         self.num_capsule, self.num_atoms))

        logit_shape = K.stack([
            input_shape[1], input_shape[0], votes_shape[1], votes_shape[2], self.num_capsule])
        biases_replicated = K.tile(self.b, [conv_height.value, conv_width.value, 1, 1])

        activations = update_routing(
            votes=votes,
            biases=biases_replicated,
            logit_shape=logit_shape,
            num_dims=6,
            input_dim=self.input_num_capsule,
            output_dim=self.num_capsule,
            num_routing=self.routings)

        return activations

    def compute_output_shape(self, input_shape):
        space = input_shape[1:-2]
        new_space = []
        for i in range(len(space)):
            new_dim = conv_output_length(
                space[i],
                self.kernel_size,
                padding=self.padding,
                stride=self.strides,
                dilation=1)
            new_space.append(new_dim)

        return (input_shape[0],) + tuple(new_space) + (self.num_capsule, self.num_atoms)

    def get_config(self):
        config = {
            'kernel_size': self.kernel_size,
            'num_capsule': self.num_capsule,
            'num_atoms': self.num_atoms,
            'strides': self.strides,
            'padding': self.padding,
            'routings': self.routings,
            'kernel_initializer': initializers.serialize(self.kernel_initializer)
        }
        base_config = super(ConvCapsuleLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


class DeconvCapsuleLayer(layers.Layer):
    def __init__(self, kernel_size, num_capsule, num_atoms, scaling=2, upsamp_type='deconv', padding='same', routings=3,
                 kernel_initializer='he_normal', **kwargs):
        super(DeconvCapsuleLayer, self).__init__(**kwargs)
        self.kernel_size = kernel_size
        self.num_capsule = num_capsule
        self.num_atoms = num_atoms
        self.scaling = scaling
        self.upsamp_type = upsamp_type
        self.padding = padding
        self.routings = routings
        self.kernel_initializer = initializers.get(kernel_initializer)

    def build(self, input_shape):
        assert len(input_shape) == 5, "The input Tensor should have shape=[None, input_height, input_width," \
                                      " input_num_capsule, input_num_atoms]"
        self.input_height = input_shape[1]
        self.input_width = input_shape[2]
        self.input_num_capsule = input_shape[3]
        self.input_num_atoms = input_shape[4]

        # Transform matrix
        if self.upsamp_type == 'subpix':
            self.W = self.add_weight(shape=[self.kernel_size, self.kernel_size,
                                            self.input_num_atoms,
                                            self.num_capsule * self.num_atoms * self.scaling * self.scaling],
                                     initializer=self.kernel_initializer,
                                     name='W')
        elif self.upsamp_type == 'resize':
            self.W = self.add_weight(shape=[self.kernel_size, self.kernel_size,
                                     self.input_num_atoms, self.num_capsule * self.num_atoms],
                                     initializer=self.kernel_initializer, name='W')
        elif self.upsamp_type == 'deconv':
            self.W = self.add_weight(shape=[self.kernel_size, self.kernel_size,
                                            self.num_capsule * self.num_atoms, self.input_num_atoms],
                                     initializer=self.kernel_initializer, name='W')
        else:
            raise NotImplementedError('Upsampling must be one of: "deconv", "resize", or "subpix"')

        self.b = self.add_weight(shape=[1, 1, self.num_capsule, self.num_atoms],
                                 initializer=initializers.constant(0.1),
                                 name='b')

        self.built = True

    def call(self, input_tensor, training=None):
        input_transposed = tf.transpose(input_tensor, [3, 0, 1, 2, 4])
        input_shape = K.shape(input_transposed)
        input_tensor_reshaped = K.reshape(input_transposed, [
            input_shape[1] * input_shape[0], self.input_height, self.input_width, self.input_num_atoms])
        input_tensor_reshaped.set_shape((None, self.input_height, self.input_width, self.input_num_atoms))


        if self.upsamp_type == 'resize':
            upsamp = K.resize_images(input_tensor_reshaped, self.scaling, self.scaling, 'channels_last')
            outputs = K.conv2d(upsamp, kernel=self.W, strides=(1, 1), padding=self.padding, data_format='channels_last')
        elif self.upsamp_type == 'subpix':
            conv = K.conv2d(input_tensor_reshaped, kernel=self.W, strides=(1, 1), padding='same',
                            data_format='channels_last')
            outputs = tf.depth_to_space(conv, self.scaling)
        else:
            batch_size = input_shape[1] * input_shape[0]

            # Infer the dynamic output shape:
            out_height = deconv_length(self.input_height, self.scaling, self.kernel_size, self.padding, 2)
            out_width = deconv_length(self.input_width, self.scaling, self.kernel_size, self.padding, 2)
            output_shape = (batch_size, out_height, out_width, self.num_capsule * self.num_atoms)

            outputs = K.conv2d_transpose(input_tensor_reshaped, self.W, output_shape, (self.scaling, self.scaling),
                                     padding=self.padding, data_format='channels_last')

        votes_shape = K.shape(outputs)
        _, conv_height, conv_width, _ = outputs.get_shape()

        votes = K.reshape(outputs, [input_shape[1], input_shape[0], votes_shape[1], votes_shape[2],
                                 self.num_capsule, self.num_atoms])
        votes.set_shape((None, self.input_num_capsule, conv_height.value, conv_width.value,
                         self.num_capsule, self.num_atoms))

        logit_shape = K.stack([
            input_shape[1], input_shape[0], votes_shape[1], votes_shape[2], self.num_capsule])
        biases_replicated = K.tile(self.b, [votes_shape[1], votes_shape[2], 1, 1])

        activations = update_routing(
            votes=votes,
            biases=biases_replicated,
            logit_shape=logit_shape,
            num_dims=6,
            input_dim=self.input_num_capsule,
            output_dim=self.num_capsule,
            num_routing=self.routings)

        return activations

    def compute_output_shape(self, input_shape):
        output_shape = list(input_shape)

        output_shape[1] = deconv_length(output_shape[1], self.scaling, self.kernel_size, self.padding,2)
        output_shape[2] = deconv_length(output_shape[2], self.scaling, self.kernel_size, self.padding,2)
        output_shape[3] = self.num_capsule
        output_shape[4] = self.num_atoms

        return tuple(output_shape)

    def get_config(self):
        config = {
            'kernel_size': self.kernel_size,
            'num_capsule': self.num_capsule,
            'num_atoms': self.num_atoms,
            'scaling': self.scaling,
            'padding': self.padding,
            'upsamp_type': self.upsamp_type,
            'routings': self.routings,
            'kernel_initializer': initializers.serialize(self.kernel_initializer)
        }
        base_config = super(DeconvCapsuleLayer, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


def update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,
                    num_routing):
    if num_dims == 6:
        votes_t_shape = [5, 0, 1, 2, 3, 4]
        r_t_shape = [1, 2, 3, 4, 5, 0]
    elif num_dims == 4:
        votes_t_shape = [3, 0, 1, 2]
        r_t_shape = [1, 2, 3, 0]
    else:
        raise NotImplementedError('Not implemented')

    votes_trans = tf.transpose(votes, votes_t_shape)
    _, _, _, height, width, caps = votes_trans.get_shape()

    def _body(i, logits, activations):
        """Routing while loop."""
        # route: [batch, input_dim, output_dim, ...]
        route = tf.nn.softmax(logits, axis=-1)
        preactivate_unrolled = route * votes_trans
        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)
        preactivate = tf.reduce_sum(preact_trans, axis=1) + biases
        activation = _squash(preactivate)
        activations = activations.write(i, activation)
        act_3d = K.expand_dims(activation, 1)
        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()
        tile_shape[1] = input_dim
        act_replicated = tf.tile(act_3d, tile_shape)
        distances = tf.reduce_sum(votes * act_replicated, axis=-1)
        logits += distances
        return (i + 1, logits, activations)

    activations = tf.TensorArray(
      dtype=tf.float32, size=num_routing, clear_after_read=False)
    logits = tf.fill(logit_shape, 0.0)

    i = tf.constant(0, dtype=tf.int32)
    _, logits, activations = tf.while_loop(
      lambda i, logits, activations: i < num_routing,
      _body,
      loop_vars=[i, logits, activations],
      swap_memory=True)

    return K.cast(activations.read(num_routing - 1), dtype='float32')


def _squash(input_tensor):
    norm = tf.norm(input_tensor, axis=-1, keepdims=True)
    norm_squared = norm * norm
    return (input_tensor / norm) * (norm_squared / (1 + norm_squared))


from keras import layers, models
from keras import backend as K
    
K.set_image_data_format('channels_last')

def CapsNetBasic(input_shape, n_class=2):
    x = layers.Input(shape=input_shape)

    # Layer 1: Just a conventional Conv2D layer
    conv1 = layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1')(x)

    # Reshape layer to be 1 capsule x [filters] atoms
    _, H, W, C = conv1.get_shape()
    conv1_reshaped = layers.Reshape((H.value, W.value, 1, C.value))(conv1)

    # Layer 1: Primary Capsule: Conv cap with routing 1
    primary_caps = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=32, strides=1, padding='same',
                                    routings=1, name='primarycaps')(conv1_reshaped)

    # Layer 4: Convolutional Capsule: 1x1
    seg_caps = ConvCapsuleLayer(kernel_size=1, num_capsule=1, num_atoms=16, strides=1, padding='same',
                                routings=3, name='seg_caps')(primary_caps)

    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.
    out_seg = Length(num_classes=n_class, seg=True, name='out_seg')(seg_caps)

    # Decoder network.
    _, H, W, C, A = seg_caps.get_shape()
    y = layers.Input(shape=input_shape[:-1]+(1,))
    masked_by_y = Mask()([seg_caps, y])  # The true label is used to mask the output of capsule layer. For training
    masked = Mask()(seg_caps)  # Mask using the capsule with maximal length. For prediction

    def shared_decoder(mask_layer):
        recon_remove_dim = layers.Reshape((H.value, W.value, A.value))(mask_layer)

        recon_1 = layers.Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_1')(recon_remove_dim)

        recon_2 = layers.Conv2D(filters=128, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_2')(recon_1)

        out_recon = layers.Conv2D(filters=1, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                  activation='sigmoid', name='out_recon')(recon_2)

        return out_recon

    # Models for training and evaluation (prediction)
    train_model = models.Model(inputs=[x, y], outputs=[out_seg, shared_decoder(masked_by_y)])
    eval_model = models.Model(inputs=x, outputs=[out_seg, shared_decoder(masked)])

    # manipulate model
    noise = layers.Input(shape=((H.value, W.value, C.value, A.value)))
    noised_seg_caps = layers.Add()([seg_caps, noise])
    masked_noised_y = Mask()([noised_seg_caps, y])
    manipulate_model = models.Model(inputs=[x, y, noise], outputs=shared_decoder(masked_noised_y))

    return train_model, eval_model, manipulate_model

def CapsNetR3(input_shape, n_class=2, enable_decoder=True):
    x = layers.Input(shape=input_shape) # x=keras_shape(None, 512, 512, 3)

    # Layer 1: Just a conventional Conv2D layer
    conv1 = layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1')(x)

    # Reshape layer to be 1 capsule x [filters] atoms
    _, H, W, C = conv1.get_shape() # _, 512, 512, 16
    conv1_reshaped = layers.Reshape((H.value, W.value, 1, C.value))(conv1)

    # Layer 1: Primary Capsule: Conv cap with routing 1
    primary_caps = ConvCapsuleLayer(kernel_size=5, num_capsule=2, num_atoms=16, strides=2, padding='same',
                                    routings=1, name='primarycaps')(conv1_reshaped)

    # Layer 2: Convolutional Capsule
    conv_cap_2_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=16, strides=1, padding='same',
                                    routings=3, name='conv_cap_2_1')(primary_caps)

    # Layer 2: Convolutional Capsule
    conv_cap_2_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=32, strides=2, padding='same',
                                    routings=3, name='conv_cap_2_2')(conv_cap_2_1)

    # Layer 3: Convolutional Capsule
    conv_cap_3_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=32, strides=1, padding='same',
                                    routings=3, name='conv_cap_3_1')(conv_cap_2_2)

    # Layer 3: Convolutional Capsule
    conv_cap_3_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=64, strides=2, padding='same',
                                    routings=3, name='conv_cap_3_2')(conv_cap_3_1)

    # Layer 4: Convolutional Capsule
    conv_cap_4_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=32, strides=1, padding='same',
                                    routings=3, name='conv_cap_4_1')(conv_cap_3_2)

    # Layer 1 Up: Deconvolutional Capsule
    deconv_cap_1_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=8, num_atoms=32, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_1_1')(conv_cap_4_1)

    # Skip connection
    up_1 = layers.Concatenate(axis=-2, name='up_1')([deconv_cap_1_1, conv_cap_3_1])

    # Layer 1 Up: Deconvolutional Capsule
    deconv_cap_1_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=32, strides=1,
                                      padding='same', routings=3, name='deconv_cap_1_2')(up_1)

    # Layer 2 Up: Deconvolutional Capsule
    deconv_cap_2_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=4, num_atoms=16, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_2_1')(deconv_cap_1_2)

    # Skip connection
    up_2 = layers.Concatenate(axis=-2, name='up_2')([deconv_cap_2_1, conv_cap_2_1])

    # Layer 2 Up: Deconvolutional Capsule
    deconv_cap_2_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=16, strides=1,
                                      padding='same', routings=3, name='deconv_cap_2_2')(up_2)

    # Layer 3 Up: Deconvolutional Capsule
    deconv_cap_3_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=2, num_atoms=16, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_3_1')(deconv_cap_2_2)

    # Skip connection
    up_3 = layers.Concatenate(axis=-2, name='up_3')([deconv_cap_3_1, conv1_reshaped])

    # Layer 4: Convolutional Capsule: 1x1
    seg_caps = ConvCapsuleLayer(kernel_size=1, num_capsule=1, num_atoms=16, strides=1, padding='same',
                                routings=3, name='seg_caps')(up_3)

    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.
    out_seg = Length(num_classes=n_class, seg=True, name='out_seg')(seg_caps)

    # Decoder network.
    _, H, W, C, A = seg_caps.get_shape() #(?, 512, 512, 1, 16)
    y = layers.Input(shape=input_shape[:-1]+(1,)) #y: keras_shape(512, 512, 1)
    masked_by_y = Mask()([seg_caps, y])  # The true label is used to mask the output of capsule layer. For training (None, 512, 512, 1, 16)
    masked = Mask()(seg_caps)  # Mask using the capsule with maximal length. For prediction ()

    def shared_decoder(mask_layer):
        recon_remove_dim = layers.Reshape((H.value, W.value, A.value))(mask_layer) #mask_layer=(?, 512, 512, 1, 16)

        recon_1 = layers.Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_1')(recon_remove_dim)

        recon_2 = layers.Conv2D(filters=128, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_2')(recon_1)

        out_recon = layers.Conv2D(filters=1, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                  activation='sigmoid', name='out_recon')(recon_2)

        return out_recon

    # Models for training and evaluation (prediction)
    train_model = models.Model(inputs=[x, y], outputs=[out_seg, shared_decoder(masked_by_y)])
    if enable_decoder == True:
        eval_model = models.Model(inputs=x, outputs=[out_seg, shared_decoder(masked)])
    else:
        eval_model = models.Model(inputs=x, outputs=[out_seg])
    # manipulate model
    noise = layers.Input(shape=((H.value, W.value, C.value, A.value)))
    noised_seg_caps = layers.Add()([seg_caps, noise])
    masked_noised_y = Mask()([noised_seg_caps, y])
    manipulate_model = models.Model(inputs=[x, y, noise], outputs=shared_decoder(masked_noised_y))

    return train_model, eval_model, manipulate_model
  
def CapsNetR1(input_shape, n_class=2):
    x = layers.Input(shape=input_shape)

    # Layer 1: Just a conventional Conv2D layer
    conv1 = layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1')(x)

    # Reshape layer to be 1 capsule x [filters] atoms
    _, H, W, C = conv1.get_shape()
    conv1_reshaped = layers.Reshape((H.value, W.value, 1, C.value))(conv1)

    # Layer 1: Primary Capsule: Conv cap with routing 1
    primary_caps = ConvCapsuleLayer(kernel_size=5, num_capsule=2, num_atoms=16, strides=2, padding='same',
                                    routings=1, name='primarycaps')(conv1_reshaped)

    # Layer 2: Convolutional Capsule
    conv_cap_2_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=16, strides=1, padding='same',
                                    routings=1, name='conv_cap_2_1')(primary_caps)

    # Layer 2: Convolutional Capsule
    conv_cap_2_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=32, strides=2, padding='same',
                                    routings=3, name='conv_cap_2_2')(conv_cap_2_1)

    # Layer 3: Convolutional Capsule
    conv_cap_3_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=32, strides=1, padding='same',
                                    routings=1, name='conv_cap_3_1')(conv_cap_2_2)

    # Layer 3: Convolutional Capsule
    conv_cap_3_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=64, strides=2, padding='same',
                                    routings=3, name='conv_cap_3_2')(conv_cap_3_1)

    # Layer 4: Convolutional Capsule
    conv_cap_4_1 = ConvCapsuleLayer(kernel_size=5, num_capsule=8, num_atoms=32, strides=1, padding='same',
                                    routings=1, name='conv_cap_4_1')(conv_cap_3_2)

    # Layer 1 Up: Deconvolutional Capsule
    deconv_cap_1_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=8, num_atoms=32, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_1_1')(conv_cap_4_1)

    # Skip connection
    up_1 = layers.Concatenate(axis=-2, name='up_1')([deconv_cap_1_1, conv_cap_3_1])

    # Layer 1 Up: Deconvolutional Capsule
    deconv_cap_1_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=32, strides=1,
                                      padding='same', routings=1, name='deconv_cap_1_2')(up_1)

    # Layer 2 Up: Deconvolutional Capsule
    deconv_cap_2_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=4, num_atoms=16, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_2_1')(deconv_cap_1_2)

    # Skip connection
    up_2 = layers.Concatenate(axis=-2, name='up_2')([deconv_cap_2_1, conv_cap_2_1])

    # Layer 2 Up: Deconvolutional Capsule
    deconv_cap_2_2 = ConvCapsuleLayer(kernel_size=5, num_capsule=4, num_atoms=16, strides=1,
                                      padding='same', routings=1, name='deconv_cap_2_2')(up_2)

    # Layer 3 Up: Deconvolutional Capsule
    deconv_cap_3_1 = DeconvCapsuleLayer(kernel_size=4, num_capsule=2, num_atoms=16, upsamp_type='deconv',
                                        scaling=2, padding='same', routings=3,
                                        name='deconv_cap_3_1')(deconv_cap_2_2)

    # Skip connection
    up_3 = layers.Concatenate(axis=-2, name='up_3')([deconv_cap_3_1, conv1_reshaped])

    # Layer 4: Convolutional Capsule: 1x1
    seg_caps = ConvCapsuleLayer(kernel_size=1, num_capsule=1, num_atoms=16, strides=1, padding='same',
                                routings=1, name='seg_caps')(up_3)

    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.
    out_seg = Length(num_classes=n_class, seg=True, name='out_seg')(seg_caps)

    # Decoder network.
    _, H, W, C, A = seg_caps.get_shape()
    y = layers.Input(shape=input_shape[:-1]+(1,))
    masked_by_y = Mask()([seg_caps, y])  # The true label is used to mask the output of capsule layer. For training
    masked = Mask()(seg_caps)  # Mask using the capsule with maximal length. For prediction

    def shared_decoder(mask_layer):
        recon_remove_dim = layers.Reshape((H.value, W.value, A.value))(mask_layer)

        recon_1 = layers.Conv2D(filters=64, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_1')(recon_remove_dim)

        recon_2 = layers.Conv2D(filters=128, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                activation='relu', name='recon_2')(recon_1)

        out_recon = layers.Conv2D(filters=1, kernel_size=1, padding='same', kernel_initializer='he_normal',
                                  activation='sigmoid', name='out_recon')(recon_2)

        return out_recon

    # Models for training and evaluation (prediction)
    train_model = models.Model(inputs=[x, y], outputs=[out_seg, shared_decoder(masked_by_y)])
    eval_model = models.Model(inputs=x, outputs=[out_seg, shared_decoder(masked)])

    # manipulate model
    noise = layers.Input(shape=((H.value, W.value, C.value, A.value)))
    noised_seg_caps = layers.Add()([seg_caps, noise])
    masked_noised_y = Mask()([noised_seg_caps, y])
    manipulate_model = models.Model(inputs=[x, y, noise], outputs=shared_decoder(masked_noised_y))

    return train_model, eval_model, manipulate_model
################################################################## Model End ##################################################################


from keras import backend as K
smooth = 1
def dice_coef(y_true, y_pred):
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)
  
def margin_loss(margin=0.4, downweight=0.5, pos_weight=1.0):

    def _margin_loss(labels, raw_logits):
        
        logits = raw_logits - 0.5
        positive_cost = pos_weight * labels * tf.cast(tf.less(logits, margin),
                                       tf.float32) * tf.pow(logits - margin, 2)
        negative_cost = (1 - labels) * tf.cast(
          tf.greater(logits, -margin), tf.float32) * tf.pow(logits + margin, 2)
        return 0.5 * positive_cost + downweight * 0.5 * negative_cost

    return _margin_loss

def dice_soft(y_true, y_pred, loss_type='jaccard', axis=[1,2,3], smooth=1e-5, from_logits=False):
    
    if not from_logits:
        # transform back to logits
        _epsilon = tf.convert_to_tensor(1e-7, y_pred.dtype.base_dtype)
        y_pred = tf.clip_by_value(y_pred, _epsilon, 1 - _epsilon)
        y_pred = tf.log(y_pred / (1 - y_pred))

    inse = tf.reduce_sum(y_pred * y_true, axis=axis)
    if loss_type == 'jaccard':
        l = tf.reduce_sum(y_pred * y_pred, axis=axis)
        r = tf.reduce_sum(y_true * y_true, axis=axis)
    elif loss_type == 'sorensen':
        l = tf.reduce_sum(y_pred, axis=axis)
        r = tf.reduce_sum(y_true, axis=axis)
    else:
        raise Exception("Unknow loss_type")
        
    dice = (2. * inse + smooth) / (l + r + smooth)
    dice = tf.reduce_mean(dice)
    return dice

def dice_loss(y_true, y_pred, from_logits=False):
    return 1-dice_soft(y_true, y_pred, from_logits=False)

def load_weights (y_train):
    pos=float(np.count_nonzero(ytrain))
    neg=float(ytrain.size)
    return pos/neg

def weighted_binary_crossentropy_loss(pos_weight):
    # pos_weight: A coefficient to use on the positive examples.
    def weighted_binary_crossentropy(target, output, from_logits=False):
        """Binary crossentropy between an output tensor and a target tensor.
        # Arguments
            target: A tensor with the same shape as `output`.
            output: A tensor.
            from_logits: Whether `output` is expected to be a logits tensor.
                By default, we consider that `output`
                encodes a probability distribution.
        # Returns
            A tensor.
        """
        # Note: tf.nn.sigmoid_cross_entropy_with_logits
        # expects logits, Keras expects probabilities.
        if not from_logits:
            # transform back to logits
            _epsilon = tf.convert_to_tensor(1e-7, output.dtype.base_dtype)
            output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)
            output = tf.log(output / (1 - output))

        return tf.nn.weighted_cross_entropy_with_logits(targets=target,logits=output,pos_weight=pos_weight)
    return weighted_binary_crossentropy

################################# Play Ground #######################################################
inputShape=(256, 256, 1)
tmodel= CapsNetR3(inputShape,2,False)
model=tmodel[0]

# print('------------------------------Multi GPU settings -------------------------------')
# model = multi_gpu_model(model,gpus=2)
# print('--------------------------------------------------------------------------------')


########################### weight loading######################################################
"""import os 

os.chdir('/home/cse_jeny/Anubhav/FCD_1_5T_Mix/10')
cwd = os.getcwd() 
print("Current working directory is:", cwd) 

model.load_weights('val_out_seg_dice_coef.h5')"""

################################################################################################

#loss = 'binary_crossentropy'

margin_l = margin_loss(margin=0.4, downweight=0.5, pos_weight=1.0)

#w_bce=weighted_binary_crossentropy_loss(load_weights (ytrain))

#loss , loss_weights={'out_seg': 'binary_crossentropy', 'out_recon': 'mse'}, {'out_seg': 1., 'out_recon': 0.392}
#model.compile(optimizer = optimiser, loss = loss, loss_weights=loss_weights, metrics = ['accuracy',dice_coef])
lr=0.001
#optimiser= Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon = 0.1, decay = 1e-6) 

##############################################      Optimiser     #################################################
optimiser= Adam() 
#optimiser=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)
#optimiser=Adam(amsgrad=True)
model.compile(optimizer = optimiser, loss = ['binary_crossentropy','mse'], loss_weights=[1.,0.392], metrics = ['accuracy',dice_coef])
#class_weights = class_weight.compute_class_weight('balanced',np.unique(np.squeeze(ytrain)), ytrain)
#class_weights = {0: 1.,1: 50.}    
tmodel[1].summary()

import os 

# os.chdir('/home/jenyrajan/Major_Project_Seg_Caps_2020/Positive_Random/Results-1100epochs-segcaps')
# cwd = os.getcwd() 
# print("Current working directory is:", cwd) 

# #cv = CSVLogger('Results-1100epochs-segcaps.csv',append=True)
# lr_decay = LearningRateScheduler(schedule=lambda epoch: lr * (0.9 ** epoch))
# tensorboard_callback = TensorBoard( histogram_freq=1)
# lr_reducer = ReduceLROnPlateau(monitor='val_out_seg_dice_coef', factor=0.05, cooldown=0, patience=50,verbose=1, mode='max')

# out_seg_loss = ModelCheckpoint('out_seg_loss.h5', verbose=1,monitor='out_seg_loss', mode='min', save_best_only=True)
# t_loss = ModelCheckpoint('loss.h5', verbose=1,monitor='loss', mode='min', save_best_only=True)
# val_out_seg_loss = ModelCheckpoint('val_out_seg_loss.h5', verbose=1,monitor='val_out_seg_loss', mode='min', save_best_only=True)
# val_out_seg_dice_coef = ModelCheckpoint('val_out_seg_dice_coef.h5', verbose=1,monitor='val_out_seg_dice_coef', mode='max', save_best_only=True)

#  model.fit([xtrain, ytrain], [ytrain, xtrain*ytrain],verbose = 0,batch_size=1,epochs=1100, 
# #           validation_data=([xval, yval], [yval, xval*yval]),callbacks=[cv,out_seg_loss,t_loss,val_out_seg_loss,val_out_seg_dice_coef,tensorboard_callback])




######################################################   Test & Val Metrics Calculation   #############################################################
import matplotlib.pyplot as plt
import matplotlib

print('==============================   Test & Val Metrics Calculation   ==============================================')
#Test--------------------------
import matplotlib.pyplot as plt
import matplotlib
from medpy.metric import dc, precision, recall

os.chdir('/home/jenyrajan/Major_Project_Seg_Caps_2020/Positive_Random/Results-1100epochs-segcaps')
cwd = os.getcwd() 
print("Current working directory is:", cwd) 
#model.load_weights('out_seg_loss.h5')
#model.load_weights('loss.h5')
model.load_weights('val_out_seg_dice_coef.h5')
#model.load_weights('val_out_seg_dice_coef.h5')
# left val_out_seg_loss
# right out_seg_loss
emodel=tmodel[1]

pred = emodel.predict(xtest,batch_size=1)
test_result=np.array(pred)
test_result = np.zeros(test_result.shape)
test_result[pred>0.5] = 1
test_result[pred<=0.5] = 0
dice = dc(test_result, ytest)
pre  = precision(test_result,ytest)
re   = recall(test_result,ytest)
print('------------------Test----------------------')
print("Dice Coef: ",dice)
print("Precision: ",pre)
print("Recall   : ",re)
print('--------------------------------------------')

pred = emodel.predict(xval,batch_size=1)
test_result=np.array(pred)
test_result = np.zeros(test_result.shape)
test_result[pred>0.5] = 1
test_result[pred<=0.5] = 0
dice = dc(test_result, yval)
pre  = precision(test_result,yval)
re   = recall(test_result,yval)
print('------------------Val-----------------------')
print("Dice Coef: ",dice)
print("Precision: ",pre)
print("Recall   : ",re)
print('--------------------------------------------')

print('===============================================================================================')

#############################################################################################################################################################
"""
#model.load_weights('out_seg_loss.h5')
#model.load_weights('loss.h5')
#model.load_weights('val_out_seg_loss.h5')
model.load_weights('val_out_seg_dice_coef.h5')

emodel=tmodel[1]
emodel.compile(optimizer = optimiser, loss = 'binary_crossentropy', metrics = ['accuracy',dice_coef])
pred = emodel.evaluate(xtest,ytest,batch_size=1)
print("Evaluate",pred[2])
"""
######################################################   Image, Ground Truth and Prediction   #############################################################

'''print('================================  Image, Ground Truth and Prediction =========================================')
#Test--------------------------
import matplotlib.pyplot as plt
import matplotlib
from medpy.metric import dc, precision, recall

os.chdir('/home/cse_jeny/Anubhav/FCD_3T_PositiveAndRandom/split5/01')
cwd = os.getcwd() 
print("Current working directory is:", cwd) 

#model.load_weights('out_seg_loss.h5')
#model.load_weights('loss.h5')
model.load_weights('val_out_seg_loss.h5')
#model.load_weights('val_out_seg_dice_coef.h5')

emodel=tmodel[1]

###Test###
pred = emodel.predict(xtest,batch_size=1)
test_result=np.array(pred)
test_result = np.zeros(test_result.shape)
test_result[pred>0.5] = 1
test_result[pred<=0.5] = 0
dice = dc(test_result, ytest)
pre  = precision(test_result,ytest)
re   = recall(test_result,ytest)
print('------------------Test----------------------')
print("Dice Coef: ",dice)
print("Precision: ",pre)
print("Recall   : ",re)
print('--------------------------------------------')
'''
os.chdir('/home/jenyrajan/PAWAN/2020/FCD/Data/Positive_Random/')
cwd = os.getcwd() 
print("Current working directory is:", cwd)
for index in range(xtrain.shape[0]):
    matplotlib.image.imsave('Train_'+str(index+1)+'.png', xtrain[index, :, :, 0], cmap='Greys_r')
    matplotlib.image.imsave('Train_'+str(index+1)+'g.png',ytrain[index, :, :, 0]*255, cmap='Greys_r')
    #matplotlib.image.imsave('Test_'+str(index+1)+'p.png',test_result[index,:,:,0]*255, cmap='Greys_r')
"""
###Val### 
pred = emodel.predict(xval,batch_size=1)
test_result=np.array(pred)
test_result = np.zeros(test_result.shape)
test_result[pred>0.5] = 1
test_result[pred<=0.5] = 0
dice = dc(test_result, yval)
pre  = precision(test_result,yval)
re   = recall(test_result,yval)
print('------------------Val-----------------------')
print("Dice Coef: ",dice)
print("Precision: ",pre)
print("Recall   : ",re)
print('--------------------------------------------')

os.chdir('/home/cse_jeny/Anubhav/FCD_3T_PositiveAndRandom/split5/01/predval')
cwd = os.getcwd() 
print("Current working directory is:", cwd)
for index in range(xval.shape[0]):
    matplotlib.image.imsave('Val_'+str(index+1)+'.jpg', xval[index, :, :, 0], cmap='Greys_r')
    matplotlib.image.imsave('Val_'+str(index+1)+'g.jpg',yval[index, :, :, 0]*255, cmap='Greys_r')
    matplotlib.image.imsave('Val_'+str(index+1)+'p.jpg',test_result[index,:,:,0]*255, cmap='Greys_r')

print('===================================================================================================================')
"""
#############################################################################################################################################################



"""from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
    rotation_range=15,
    horizontal_flip=True,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.3
    )
datagen.fit(xtrain)
log=model.fit_generator(datagen.flow([xtrain, ytrain], [ytrain, xtrain], batch_size=1),steps_per_epoch = len(xtrain), epochs=300, callbacks=[mc,cv,lc], validation_data=([xval, yval], [yval, xval]))"""

"""
import os 

os.chdir('/home/cse_jeny/Anubhav/FCD_1_5T_Mix/08')
cwd = os.getcwd() 
print("Current working directory is:", cwd) 


#tmodel3= CapsNetR3(inputShape,2,False)
#model3=tmodel[0]

model.load_weights('org_val_out_seg_dice_coef_300.h5')
emodel=tmodel[1]

from keras import backend as K

def recall_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

def precision_m(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision




#Test--------------------------
import matplotlib.pyplot as plt
import matplotlib
from medpy.metric import dc, precision, recall
dcc=[]
prec=[]
rec=[]


for index in range(79):
    pred = emodel.predict(xtest[index:index+1])
    test_result=np.array(pred)
    test_result = np.zeros(test_result.shape)
    test_result[pred>0.5] = 1
    test_result[pred<=0.5] = 0
    #print( ytest[0:1].shape,test_result.shape)
    dice = dc(test_result, ytest[index:index+1])
    pre  = precision(test_result,ytest[index:index+1])
    re   = recall(test_result,ytest[index:index+1])
    dcc.append(dice)
    prec.append(pre)
    rec.append(re)
    matplotlib.image.imsave(str(index+1)+'.jpg', xtest[index, :, :, 0], cmap='Greys_r')
    matplotlib.image.imsave(str(index+1)+'g.jpg',ytest[index, :, :, 0]*255, cmap='Greys_r')
    matplotlib.image.imsave(str(index+1)+'p.jpg',test_result[0,:,:,0]*255, cmap='Greys_r')


print(dcc)
print(prec)
print(rec)

print( 'Dice:',sum(dcc) / len(dcc) )
print( 'Precision:',sum(prec) / len(prec) )    
print( 'recall:',sum(rec) / len(rec) )

emodel.compile(optimizer = optimiser, loss = 'binary_crossentropy',  metrics = ['accuracy',dice_coef,keras.metrics.Precision(), keras.metrics.Recall()])

dcc=[]
prec=[]
rec=[]


for index in range(79):
    pred = emodel.evaluate(x=xtest[index:index+1],y=ytest[index:index+1])
    dcc.append(pred[2])
    prec.append(pred[3])
    rec.append(pred[4])
print(dcc)
print(prec)
print(rec)

print( 'Dice:',sum(dcc) / len(dcc) )
print( 'Precision:',sum(prec) / len(prec) )    
print( 'recall:',sum(rec) / len(rec) )"""



"""emodel.compile(optimizer = optimiser, loss = 'binary_crossentropy',  metrics = ['accuracy',dice_coef,keras.metrics.Precision(), keras.metrics.Recall()])

dcc=[]
prec=[]
rec=[]


for index in range(79):
    pred = emodel.evaluate(x=xtest[index:index+1],y=ytest[index:index+1])
    dcc.append(pred[2])
    prec.append(pred[3])
    rec.append(pred[4])
print(dcc)
print(prec)
print(rec)

print( 'Dice:',sum(dcc) / len(dcc) )
print( 'Precision:',sum(prec) / len(prec) )    
print( 'recall:',sum(rec) / len(rec) )
"""

"""
#Val--------------------------
import matplotlib.pyplot as plt
import matplotlib
from medpy.metric import dc, precision, recall
dcc=[]
prec=[]
rec=[]


for index in range(79):
    pred = emodel.predict(xval[index:index+1])
    test_result=np.array(pred)
    test_result = np.zeros(test_result.shape)
    test_result[pred>0.5] = 1.0
    test_result[pred<=0.5] = 0.0
    #print( ytest[0:1].shape,test_result.shape)
    dice = dc(test_result, yval[index:index+1])
    pre  = precision(test_result,yval[index:index+1])
    re   = recall(test_result,yval[index:index+1])
    dcc.append(dice)
    prec.append(pre)
    rec.append(re)
    #matplotlib.image.imsave(str(index+1)+'.jpg', xval[index, :, :, 0], cmap='Greys_r')
    #matplotlib.image.imsave(str(index+1)+'g.jpg',yval[index, :, :, 0]*255, cmap='Greys_r')
    #matplotlib.image.imsave(str(index+1)+'p.jpg',test_result[0,:,:,0]*255, cmap='Greys_r')


print(dcc)
print(prec)
print(rec)

print( 'Dice:',sum(dcc) / len(dcc) )
print( 'Precision:',sum(prec) / len(prec) )    
print( 'recall:',sum(rec) / len(rec) )


emodel.compile(optimizer = optimiser, loss = 'binary_crossentropy',  metrics = ['accuracy',dice_coef])

dcc=[]
prec=[]
rec=[]


for index in range(79):
    pred = emodel.evaluate(x=xval[index:index+1],y=yval[index:index+1])
    dcc.append(pred[2])
print(dcc)
print( 'Dice:',sum(dcc) / len(dcc) )"""
"""
emodel=tmodel[1]
pred = emodel.predict(xtest[9:10])

print (pred.shape)
print("Prediction ")

plt.subplot(131).imshow(np.squeeze(xtest[9:10]),cmap='gray')
plt.show()

plt.subplot(132).imshow(np.squeeze(ytest[9:10]),cmap='gray')
plt.show()

import matplotlib.pyplot as plt
plt.subplot(133).imshow(np.squeeze(pred[0]),cmap='gray')
plt.show()

print(np.squeeze(pred[0]))

test_result=np.array(pred)
test_result = np.zeros(test_result.shape)
test_result[pred>0.5] = 1
test_result[pred<=0.5] =0


dice = dc(test_result, ytest[9:10])


print (dice)

plt.imshow(np.squeeze(test_result[0]),cmap='gray')
plt.show()

from medpy.metric import dc, precision, recall
test_pred = emodel.predict(xtest[0:10])
#print(test_pred.shape)
test_result=np.array(test_pred)
test_result = np.zeros(test_result.shape)
test_result[test_pred>0.5] = 1
test_result[test_pred<=0.5] = 0
dice = dc(test_result, ytest[0:1])
pre  = precision(test_result,ytest[0:1])
re   = recall(test_result,ytest[0:1])

print(dice,pre,re)

from medpy.metric import dc, precision, recall
test_pred = emodel.predict(xtrain[0:10])
#print(test_pred.shape)
test_result=np.array(test_pred)
test_result = np.zeros(test_result.shape)
test_result[test_pred>0.5] = 1
test_result[test_pred<=0.5] = 0
dice = dc(test_result, ytrain[0:10])
pre  = precision(test_result,ytrain[0:10])
re   = recall(test_result,ytrain[0:10])

print(dice,pre,re)


#test : 0.3555062841540619 0.22416014744543603 0.8586024937520373
#val:   0.4221963215925779 0.2776107310835311 0.8810832974272729
#train :0.37149043215766553 0.23597968728648067 0.8725502021124005
mg_name[:-4]
    numpy_path = join(root_path, 'np_files')
    img_path = join(root_path, 'imgs')
    mask_path = join(root_path, 'masks')
    fig_path = join(root_path, 'figs')
    try:
        mkdir(numpy_path)
    except:
        pass
    try:
        mkdir(fig_path)
    except:
        pass

    ct_min = -1024
    ct_max = 3072

    if not overwrite:
        try:
            with n

#print(test_result[0])

from scipy.misc import imresize, imsave, imread
for i in range(0,10):
    imsave('/home/student/Desktop/Anubhav/R/'+str(i+1)+'.jpg', xtest[i, :, :, 0])
    imsave('/home/student/Desktop/Anubhav/R/'+str(i+1)+'g.jpg',ytest[i, :, :, 0]*255)
    imsave('/home/student/Desktop/Anubhav/R/'+str(i+1)+'p.jpg',test_result[i,:,:,0]*255)

results = []
for j in np.arange(100,110):
    input_img = np.expand_dims(np.expand_dims(([Ximages[j, :, :],Yimages[j, :, :]]), axis=-1, axis=0)
    results.append(model.predict(input_img, verbose=1)[0])
results = np.squeeze(np.asarray(results))
print(results)"""



